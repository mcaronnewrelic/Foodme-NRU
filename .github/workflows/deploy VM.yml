name: deploy-vm

on:
  push:
    branches: [main, master]
    paths: ["terraform/**"]
  pull_request:
    branches: [main, master]
  workflow_dispatch:
    inputs:
      environment:
        description: Environment to deploy to
        required: true
        default: staging
        type: choice
        options: [staging, production]

permissions:
  contents: read
  actions: write
  deployments: write
  id-token: write

env:
  AWS_REGION: us-west-2
  TF_VERSION: 1.6.0
  NODE_VERSION: 22
  TERRAFORM_LOCK_TIMEOUT: 15m
  TERRAFORM_RETRY_ATTEMPTS: 3
  LOCK_WAIT_INTERVAL: 30
  MAX_LOCK_WAIT_TIME: 600 # 10 minutes
jobs:
  terraform-plan:
    name: Plan Infrastructure Changes
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'staging' }}
    outputs:
      tfplan: ${{ steps.plan.outputs.tfplan }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Format Terraform files
        run: terraform fmt -recursive
        working-directory: ./terraform

      - name: Pre-validate Terraform syntax
        run: terraform validate -json
        working-directory: ./terraform
        continue-on-error: false

      - name: Check for duplicate variable declarations
        run: |
          DUPLICATE_VARS=$(grep -r "^variable " ./terraform --include="*.tf" | cut -d'"' -f2 | sort | uniq -d)
          if [ -n "$DUPLICATE_VARS" ]; then
            echo "Duplicate variable declarations found:"
            echo "$DUPLICATE_VARS"
            echo "Please remove duplicate variable declarations from your Terraform files"
            exit 1
          fi
          echo "No duplicate variables found"
        working-directory: ./terraform

      - name: Validate concurrent operations
        run: |
          LOCK_TABLE="${{ vars.TERRAFORM_LOCK_TABLE }}"
          LOCK_KEY="${{ github.event.inputs.environment || 'staging' }}/terraform.tfstate"

          # Check for existing locks
          EXISTING_LOCK=$(aws dynamodb get-item \
            --table-name "$LOCK_TABLE" \
            --key '{"LockID": {"S": "'"$LOCK_KEY"'"}}' \
            --query 'Item.Info.S' \
            --output text 2>/dev/null || echo "NONE")

          if [ "$EXISTING_LOCK" != "NONE" ] && [ "$EXISTING_LOCK" != "null" ]; then
            echo "Existing Terraform lock detected: $EXISTING_LOCK"
            echo "Waiting for lock release..."
            
            for attempt in $(seq 1 20); do
              sleep 30
              CURRENT_LOCK=$(aws dynamodb get-item \
                --table-name "$LOCK_TABLE" \
                --key '{"LockID": {"S": "'"$LOCK_KEY"'"}}' \
                --query 'Item.Info.S' \
                --output text 2>/dev/null || echo "NONE")
              
              if [ "$CURRENT_LOCK" = "NONE" ] || [ "$CURRENT_LOCK" = "null" ]; then
                echo "Lock released, proceeding with operation"
                break
              fi
              
              if [ $attempt -eq 20 ]; then
                echo "Lock still exists after 10 minutes, manual intervention required"
                exit 1
              fi
            done
          fi

      - name: Initialize Terraform
        run: |
          terraform init \
            -backend-config="bucket=${{ vars.TERRAFORM_STATE_BUCKET }}" \
            -backend-config="key=${{ github.event.inputs.environment || 'staging' }}/terraform.tfstate" \
            -backend-config="dynamodb_table=${{ vars.TERRAFORM_LOCK_TABLE }}" \
            -backend-config="region=${{ vars.AWS_REGION }}"
        working-directory: ./terraform

      - name: Final validation after initialization
        run: terraform validate
        working-directory: ./terraform

      - name: Execute Terraform plan with lock timeout
        run: |
          terraform plan \
            -var="environment=${{ github.event.inputs.environment || 'staging' }}" \
            -var="app_version=${{ github.sha }}" \
            -lock-timeout=10m \
            -out=tfplan
        working-directory: ./terraform
        timeout-minutes: 15

      - name: Archive execution plan
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan-${{ github.sha }}
          path: terraform/tfplan
          retention-days: 5

  deploy-infrastructure:
    name: Deploy Infrastructure
    runs-on: ubuntu-latest
    needs: [terraform-plan]
    environment: ${{ github.event.inputs.environment || 'staging' }}
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' || github.event_name == 'workflow_dispatch'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Download execution plan
        uses: actions/download-artifact@v4
        with:
          name: terraform-plan-${{ github.sha }}
          path: terraform/

      - name: Initialize Terraform
        run: |
          terraform init \
            -backend-config="bucket=${{ vars.TERRAFORM_STATE_BUCKET }}" \
            -backend-config="key=${{ github.event.inputs.environment || 'staging' }}/terraform.tfstate" \
            -backend-config="dynamodb_table=${{ vars.TERRAFORM_LOCK_TABLE }}" \
            -backend-config="region=${{ vars.AWS_REGION }}"
        working-directory: ./terraform

      - name: Apply infrastructure changes
        run: terraform apply -auto-approve tfplan
        working-directory: ./terraform

      - name: Extract instance information
        id: instance
        run: |
          INSTANCE_IP=$(terraform output -raw instance_public_ip)
          INSTANCE_ID=$(terraform output -raw instance_id)
          echo "ip=$INSTANCE_IP" >> $GITHUB_OUTPUT
          echo "id=$INSTANCE_ID" >> $GITHUB_OUTPUT
        working-directory: ./terraform

      - name: Configure SSH authentication
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa

          if ! ssh-keygen -l -f ~/.ssh/id_rsa > /dev/null 2>&1; then
            echo "Invalid SSH private key"
            exit 1
          fi

      - name: Wait for instance readiness
        run: |
          for attempt in {1..60}; do
            if nc -z ${{ steps.instance.outputs.ip }} 22 2>/dev/null; then
              echo "SSH port is accessible"
              break
            fi
            echo "Waiting for SSH (attempt $attempt/60)"
            sleep 5
          done
          sleep 30

      - name: Monitor deployment status
        timeout-minutes: 15
        continue-on-error: true
        run: |
          SSH_OPTS="-i ~/.ssh/id_rsa -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=10"

          timeout 30 ssh $SSH_OPTS ec2-user@${{ steps.instance.outputs.ip }} "cloud-init status --wait" || echo "Cloud-init monitoring failed"

          echo "Deployment logs:"
          timeout 30 ssh $SSH_OPTS ec2-user@${{ steps.instance.outputs.ip }} "sudo tail -n 50 /var/log/cloud-init-output.log" || echo "Could not retrieve logs"

      - name: Create deployment marker
        uses: newrelic/deployment-marker-action@v2.5.1
        with:
          guid: ${{ secrets.NEW_RELIC_APP_ID }}
          apiKey: ${{ secrets.NEW_RELIC_API_KEY }}
          region: US
          user: ${{ github.actor }}
          commit: ${{ github.sha }}
          changelog: ${{ github.event.head_commit.message }}
          version: ${{ github.ref_name }}
          description: "Deployed to ${{ github.event.inputs.environment || 'staging' }} by ${{ github.actor }}"

      - name: Generate deployment summary
        run: |
          cat >> $GITHUB_STEP_SUMMARY << EOF
          ## Deployment Summary
          - **Environment**: ${{ github.event.inputs.environment || 'staging' }}
          - **Instance ID**: ${{ steps.instance.outputs.id }}
          - **Instance IP**: ${{ steps.instance.outputs.ip }}
          - **Application URL**: http://${{ steps.instance.outputs.ip }}
          - **Commit**: ${{ github.sha }}
          - **Deployed by**: ${{ github.actor }}
          EOF

  cleanup-failed-deployment:
    name: Cleanup Failed Deployment
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure]
    if: failure() && needs.deploy-infrastructure.result == 'failure'
    environment: ${{ github.event.inputs.environment || 'staging' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Initialize Terraform
        run: |
          terraform init \
            -backend-config="bucket=${{ vars.TERRAFORM_STATE_BUCKET }}" \
            -backend-config="key=${{ github.event.inputs.environment || 'staging' }}/terraform.tfstate" \
            -backend-config="dynamodb_table=${{ vars.TERRAFORM_LOCK_TABLE }}" \
            -backend-config="region=${{ vars.AWS_REGION }}"
        working-directory: ./terraform
        continue-on-error: true

      - name: Destroy failed resources
        run: |
          terraform init \
            -backend-config="bucket=${{ vars.TERRAFORM_STATE_BUCKET }}" \
            -backend-config="key=${{ github.event.inputs.environment || 'staging' }}/terraform.tfstate" \
            -backend-config="dynamodb_table=${{ vars.TERRAFORM_LOCK_TABLE }}" \
            -backend-config="region=${{ vars.AWS_REGION }}"

          terraform destroy -auto-approve \
            -var="environment=${{ github.event.inputs.environment || 'staging' }}" \
            -var="app_version=${{ github.sha }}"
        working-directory: ./terraform
        env:
          TF_VAR_key_name: ${{ secrets.EC2_KEY_NAME }}
          TF_VAR_allowed_cidr_blocks: ${{ secrets.ALLOWED_CIDR_BLOCKS }}
        continue-on-error: true
