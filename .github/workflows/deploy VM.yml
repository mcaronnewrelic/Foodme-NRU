name: deploy-vm

on:
  push:
    branches: [main, master]
    paths: ["terraform/**"]
  pull_request:
    branches: [main, master]
  workflow_dispatch:
    inputs:
      environment:
        description: Environment to deploy to
        required: true
        default: staging
        type: choice
        options: [staging, production]
      force_unlock:
        description: Force unlock and cleanup state
        required: false
        default: false
        type: boolean

permissions:
  contents: read
  actions: write
  deployments: write
  id-token: write

env:
  AWS_REGION: us-west-2
  TF_VERSION: 1.6.0
  NODE_VERSION: 22
  TERRAFORM_LOCK_TIMEOUT: 15m
  TERRAFORM_RETRY_ATTEMPTS: 3
  LOCK_WAIT_INTERVAL: 30
  MAX_LOCK_WAIT_TIME: 600
jobs:
  cleanup-state:
    name: Cleanup Terraform State
    runs-on: ubuntu-latest
    if: github.event.inputs.force_unlock == 'true'
    environment: ${{ github.event.inputs.environment || 'staging' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Force remove DynamoDB locks
        run: |
          LOCK_TABLE="${{ secrets.TERRAFORM_LOCK_TABLE }}"
          LOCK_KEY="${{ github.event.inputs.environment || 'staging' }}/terraform.tfstate"

          echo "Attempting to remove lock for key: $LOCK_KEY"
          aws dynamodb delete-item \
            --table-name "$LOCK_TABLE" \
            --key '{"LockID": {"S": "'"$LOCK_KEY"'"}}' || echo "No lock to remove"

      - name: Delete state file from S3
        run: |
          STATE_BUCKET="${{ secrets.TERRAFORM_STATE_BUCKET }}"
          STATE_KEY="${{ github.event.inputs.environment || 'staging' }}/terraform.tfstate"

          echo "Deleting state file: s3://$STATE_BUCKET/$STATE_KEY"
          aws s3 rm "s3://$STATE_BUCKET/$STATE_KEY" || echo "State file not found"

          echo "Deleting backup state file if it exists"
          aws s3 rm "s3://$STATE_BUCKET/$STATE_KEY.backup" || echo "Backup state file not found"

      - name: Verify cleanup
        run: |
          echo "Cleanup completed. State and locks have been removed."
          echo "You can now run a fresh deployment."

  terraform-plan:
    name: Plan Infrastructure Changes
    runs-on: ubuntu-latest
    needs: [cleanup-state]
    if: always() && !cancelled() && (needs.cleanup-state.result == 'success' || needs.cleanup-state.result == 'skipped')
    environment: ${{ github.event.inputs.environment || 'staging' }}
    outputs:
      tfplan: ${{ steps.plan.outputs.tfplan }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Format Terraform files
        run: terraform fmt -recursive
        working-directory: ./terraform

      - name: Validate Terraform syntax (pre-init)
        run: |
          # Basic syntax validation without providers
          terraform fmt -check=true -diff=true ./terraform || {
            echo "Terraform files need formatting. Run 'terraform fmt -recursive' locally."
            exit 1
          }
        working-directory: ./

      - name: Check for duplicate variable declarations
        run: |
          DUPLICATE_VARS=$(grep -r "^variable " ./terraform --include="*.tf" | cut -d'"' -f2 | sort | uniq -d)
          if [ -n "$DUPLICATE_VARS" ]; then
            echo "Duplicate variable declarations found:"
            echo "$DUPLICATE_VARS"
            echo "Please remove duplicate variable declarations from your Terraform files"
            exit 1
          fi
          echo "No duplicate variables found"
        working-directory: ./terraform

      - name: Validate concurrent operations
        run: |
          LOCK_TABLE="${{ secrets.TERRAFORM_LOCK_TABLE }}"
          LOCK_KEY="${{ github.event.inputs.environment || 'staging' }}/terraform.tfstate"

          echo "Checking for existing locks on key: $LOCK_KEY"

          # Get lock status with better error handling
          LOCK_RESPONSE=$(aws dynamodb get-item \
            --table-name "$LOCK_TABLE" \
            --key '{"LockID": {"S": "'"$LOCK_KEY"'"}}' \
            --output json 2>/dev/null || echo '{}')

          # Check if Item exists in response
          HAS_ITEM=$(echo "$LOCK_RESPONSE" | jq -r 'has("Item")')

          if [ "$HAS_ITEM" = "true" ]; then
            LOCK_INFO=$(echo "$LOCK_RESPONSE" | jq -r '.Item.Info.S // "Unknown lock info"')
            echo "Active Terraform lock detected: $LOCK_INFO"
            
            if [ "${{ github.event.inputs.force_unlock }}" = "true" ]; then
              echo "Force unlock requested, removing lock..."
              aws dynamodb delete-item \
                --table-name "$LOCK_TABLE" \
                --key '{"LockID": {"S": "'"$LOCK_KEY"'"}}'
              echo "Lock removed successfully"
            else
              echo "ERROR: Terraform state is locked!"
              echo "To unlock, re-run this workflow with 'force_unlock' set to true"
              echo "Or run manually: aws dynamodb delete-item --table-name '$LOCK_TABLE' --key '{\"LockID\": {\"S\": \"$LOCK_KEY\"}}'"
              exit 1
            fi
          else
            echo "No active locks found, proceeding with deployment"
          fi

      - name: Validate Terraform files exist
        run: |
          if [ ! -d "./terraform" ]; then
            echo "ERROR: terraform directory not found"
            exit 1
          fi

          if [ ! -f "./terraform/main.tf" ]; then
            echo "ERROR: main.tf not found in terraform directory"
            exit 1
          fi

          echo "Terraform files validated"
        working-directory: ./

      - name: Check Terraform syntax before init
        run: |
          # Validate syntax without initialization
          for tf_file in $(find . -name "*.tf" -type f); do
            echo "Checking syntax of $tf_file"
            terraform fmt -check=true "$tf_file" || {
              echo "ERROR: Terraform file $tf_file has syntax errors"
              echo "Run 'terraform fmt' to fix formatting issues"
              exit 1
            }
          done
          echo "All Terraform files have valid syntax"
        working-directory: ./terraform

      - name: Initialize Terraform
        run: |
          terraform init \
            -backend-config="bucket=${{ secrets.TERRAFORM_STATE_BUCKET }}" \
            -backend-config="key=${{ github.event.inputs.environment || 'staging' }}/terraform.tfstate" \
            -backend-config="dynamodb_table=${{ secrets.TERRAFORM_LOCK_TABLE }}" \
            -backend-config="region=${{ env.AWS_REGION }}"
        working-directory: ./terraform

      - name: Validate Terraform configuration (post-init)
        run: terraform validate
        working-directory: ./terraform

      - name: Execute Terraform plan with lock timeout
        run: |
          terraform plan \
            -var="environment=${{ github.event.inputs.environment || 'staging' }}" \
            -var="app_version=${{ github.sha }}" \
            -lock-timeout=10m \
            -out=tfplan
        working-directory: ./terraform
        timeout-minutes: 15

      - name: Archive execution plan
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan-${{ github.sha }}
          path: terraform/tfplan
          retention-days: 5

  deploy-infrastructure:
    name: Deploy Infrastructure
    runs-on: ubuntu-latest
    needs: [terraform-plan]
    environment: ${{ github.event.inputs.environment || 'staging' }}
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' || github.event_name == 'workflow_dispatch'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Download execution plan
        uses: actions/download-artifact@v4
        with:
          name: terraform-plan-${{ github.sha }}
          path: terraform/

      - name: Initialize Terraform
        run: |
          terraform init \
            -backend-config="bucket=${{ secrets.TERRAFORM_STATE_BUCKET }}" \
            -backend-config="key=${{ github.event.inputs.environment || 'staging' }}/terraform.tfstate" \
            -backend-config="dynamodb_table=${{ secrets.TERRAFORM_LOCK_TABLE }}" \
            -backend-config="region=${{ env.AWS_REGION }}"
        working-directory: ./terraform

      - name: Apply infrastructure changes
        run: terraform apply -auto-approve tfplan
        working-directory: ./terraform

      - name: Extract instance information
        id: instance
        run: |
          INSTANCE_IP=$(terraform output -raw instance_public_ip)
          INSTANCE_ID=$(terraform output -raw instance_id)
          echo "ip=$INSTANCE_IP" >> $GITHUB_OUTPUT
          echo "id=$INSTANCE_ID" >> $GITHUB_OUTPUT
        working-directory: ./terraform

      - name: Configure SSH authentication
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa

          if ! ssh-keygen -l -f ~/.ssh/id_rsa > /dev/null 2>&1; then
            echo "Invalid SSH private key"
            exit 1
          fi

      - name: Wait for instance readiness
        run: |
          for attempt in {1..60}; do
            if nc -z ${{ steps.instance.outputs.ip }} 22 2>/dev/null; then
              echo "SSH port is accessible"
              break
            fi
            echo "Waiting for SSH (attempt $attempt/60)"
            sleep 5
          done
          sleep 30

      - name: Monitor deployment status
        timeout-minutes: 15
        continue-on-error: true
        run: |
          SSH_OPTS="-i ~/.ssh/id_rsa -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=10"

          timeout 30 ssh $SSH_OPTS ec2-user@${{ steps.instance.outputs.ip }} "cloud-init status --wait" || echo "Cloud-init monitoring failed"

          echo "Deployment logs:"
          timeout 30 ssh $SSH_OPTS ec2-user@${{ steps.instance.outputs.ip }} "sudo tail -n 50 /var/log/cloud-init-output.log" || echo "Could not retrieve logs"

      - name: Create deployment marker
        uses: newrelic/deployment-marker-action@v2.5.1
        with:
          guid: ${{ secrets.NEW_RELIC_APP_ID }}
          apiKey: ${{ secrets.NEW_RELIC_API_KEY }}
          region: US
          user: ${{ github.actor }}
          commit: ${{ github.sha }}
          changelog: ${{ github.event.head_commit.message }}
          version: ${{ github.ref_name }}
          description: "Deployed to ${{ github.event.inputs.environment || 'staging' }} by ${{ github.actor }}"

      - name: Generate deployment summary
        run: |
          cat >> $GITHUB_STEP_SUMMARY << EOF
          ## Deployment Summary
          - **Environment**: ${{ github.event.inputs.environment || 'staging' }}
          - **Instance ID**: ${{ steps.instance.outputs.id }}
          - **Instance IP**: ${{ steps.instance.outputs.ip }}
          - **Application URL**: http://${{ steps.instance.outputs.ip }}
          - **Commit**: ${{ github.sha }}
          - **Deployed by**: ${{ github.actor }}
          EOF

  cleanup-failed-deployment:
    name: Cleanup Failed Deployment
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure]
    if: failure() && needs.deploy-infrastructure.result == 'failure'
    environment: ${{ github.event.inputs.environment || 'staging' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Initialize Terraform
        run: |
          terraform init \
            -backend-config="bucket=${{ secrets.TERRAFORM_STATE_BUCKET }}" \
            -backend-config="key=${{ github.event.inputs.environment || 'staging' }}/terraform.tfstate" \
            -backend-config="dynamodb_table=${{ secrets.TERRAFORM_LOCK_TABLE }}" \
            -backend-config="region=${{ env.AWS_REGION }}"
        working-directory: ./terraform
        continue-on-error: true

      - name: Destroy failed resources
        run: |
          terraform destroy -auto-approve \
            -var="environment=${{ github.event.inputs.environment || 'staging' }}" \
            -var="app_version=${{ github.sha }}"
        working-directory: ./terraform
        env:
          TF_VAR_key_name: ${{ secrets.EC2_KEY_NAME }}
          TF_VAR_allowed_cidr_blocks: ${{ secrets.ALLOWED_CIDR_BLOCKS }}
        continue-on-error: true
